### Two Stream ConvNet for Action Recognition

# 박별님
1) 8p: 그래서 어떤걸 쓴다는 건지 결론이 부족
2) 11p: 실질적인 구현이 어떻게 되는지? (어떻게 유사한 작업에 대해 은닉층을 공유?)
3) 12p: Special 오타 / 멀티 클래스 선형 SVM에 대해 간단하게 소개했으면 좋았을 것
4) 13p: 혹시 Fine-Tuning이 뭔지 알고 있는지? / 여기서 말하는 Mean Subtraction이 뭔지 알고 있는지?
총평:
전반적으로 핵심내용은 다 들어간 점 좋음,
연관 키워드에 대한 설명이 부족,
이미지/글자 등의 배치 및 순서 좀 더 깔끔하게,
키워드설명 염동빈 PPT 참고 / 배치 및 순서 틀 최영환 PPT 참고


# 염동빈
1) 3p: DNN도 맞는데 보통은 CNN이라고 함 / Late Fusion이 뭔지 간단하게 설명 있었으면 좋았을 것
2) 4p: 데이터결합이 어떻게 되는지 / Input이 2갈래로 나뉘는 것인지
3) 7p: 가독성을 위해 3가지 개념을 별도 페이지로 분리했으면 좋았을 것
4) 8p: 논문에서 (a)와 (b)를 비교한게 맞는지? / (a)중 제일 좋은 것 + (b)중 제일 좋은 것을 설명한게 아닌지 확인
5) 10p: Spatial + Temporal에 대해 단방향 Multi-Task SVM Fusion 방식이 좋다고 해석하는게 좋지 않았나
6) 11p: 해당모델 -> 정확하게 Two-Stream SVM Fusion방식이라고 언급해주는 것이 좋음
          Deep Architecture -> 정확한 Deep Architecture 이름을 언급해주는 것이 좋음
          []는 Reference 논문으로부터 나옴을 나타내기위한 주석으로 특정 Network를 표기하기 위함이 아님
7) 12p: 논문리뷰를 해본 결과 본인이 결론을 내려본다면?
총평:
Multi-Task Learning 등 연결 키워드 정리 좋음,
해당모델/DeepArchitecture 등 애매모호한 표현 확실하게 언급하기,
Table 해석과 가독성에 좀 더 신경쓰고, 특정 주제 종료 시 한 줄 정리 추가되면 좋을 것


# 최영환
1) 2p: Late Fusion이 뭔지 간단하게 소개했으면 좋았을 것
2) 5p: Optical Flow에 대해 따로 별도의 페이지에 분리해 설명한 것이 좋았음
3) 8p: 2와 3을 비교했을 때, Dropout 0.9에 대해 Fine-Tuning을 통한 향상이 높은데 왜 3을 택한건지?
4) 9p: 한 마디로 Optical Flow Stacking이 성능이 좋다는 정리를 해줬으면 좋았을 것
5) 10p: Multi-Task Learning에 대한 설명이 간략하게라도 있었으면 좋았을 것
6) 11p: 3. Temporal의 경우 단방향이 85.9%로 더 높은데?
7) 11p: 그래서 한 마디로 단방향 Multi-Task Learning이 적용된 SVM Fusion 방식이 좋다고 정리했으면 좋았을 것
8) 12p: 정확한 Deep Architecture 이름을 언급해주는 것이 좋음
[]는 Reference 논문으로부터 나옴을 나타내기위한 주석으로 특정 Network를 표기하기 위함이 아님
총평:
전반적으로 가독성이 좋다고 느낌,
연결 키워드에 대한 설명이 추가되면 좋을 것,
특정 주제 종료 시 한 줄 정리 추가되면 좋을 것,
DeepArchitecture 등 애매모호한 표현 확실하게 언급하기,

=============================================================================
